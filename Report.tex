\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2022


% ready for submission
\usepackage[preprint,nonatbib]{neurips_2022}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2022}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage[backend=biber]{biblatex}
\usepackage{graphicx}
\usepackage{subcaption}

\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\addbibresource{reference.bib}


\title{Formatting Instructions For NeurIPS 2022}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Xiaoxuan Yu \\
  College of Chemistry and Molecular Engineering\\
  Peking University\\
  Beijing, China \\
  \texttt{xiaoxuan\_yu@pku.edu.cn} \\
  % examples of more authors
  \And
  Yihang Xia \\
  School of Mathematical Sciences \\
  Peking University \\
  Beijing, China\\
  \texttt{xyh-mathematics@pku.edu.cn} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle


\begin{abstract}
  The abstract paragraph should be indented \nicefrac{1}{2}~inch (3~picas) on
  both the left- and right-hand margins. Use 10~point type, with a vertical
  spacing (leading) of 11~points.  The word \textbf{Abstract} must be centered,
  bold, and in point size 12. Two line spaces precede the abstract. The abstract
  must be limited to one paragraph.
\end{abstract}

\input{overview_part_draft.tex}
\input{numerical experiments.tex}
\section{Discussion}

\subsection{Intuitive knowledge}

Roughly speaking, this article allows for the design of optimization
methods via direct discretization using Runge-Kutta integrators. However, the two
assumptions required would be essential. \textbf{Assumption 1} quantifies the local flatness
of convex functions in a way, and it actually contradicts our normal impression that
gradient descent converges fast when the objective is not flat. This innovative discovery
may inspire people to hold a more modern opinion towards the connection between
convergence and local flatness. Also, the article claims that with careful
analysis, discretizing ODE can preserve some of its trajectories properties.
As a result, making further research on continuous ODE or appling the KR method to
more general ODE cases can be valuable.

\subsection{Potential research directions}

To make further steps, there are quite some choices to take. The article uses conditions
of higher-order differentiability to finally achieve an algorithm involving only
first-order differential. We can see if allowing second and higher-order differential in
the final algorithm will make things different, though in that case NAG method
would be useless so we have to find another acceleration method to start with. Furthermore,
as discussed above, the influence of local flatness to the convergence behaviour in
discretized integraters is worth digging. How does the process of integration approaching
actually work? What's the instinctive impact of local differentials and higher-order
differentials? With techniques we know, some new results might be discovered.\\\\
To make a bold move, adding some random part to the conditions might leads to some
interesting facts.\\\\
\textcolor{red}{If someone comes up with more technical idea or just something creative,
  we can add here.}


\printbibliography

\end{document}